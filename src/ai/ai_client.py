"""
AI Client - Interface to LLM APIs (OpenAI compatible).
Supports OpenAI, DeepSeek, Claude, and other OpenAI-compatible providers.
"""
import os
from typing import List, Dict, Optional, Callable
from openai import OpenAI
from PyQt6.QtCore import QObject, pyqtSignal, QThread
from dotenv import load_dotenv

# Load environment variables
# Try to load from project root
env_loaded = load_dotenv()
if not env_loaded:
    # Try loading from parent directory (src/)
    load_dotenv('../.env')


class AIResponseThread(QThread):
    """
    Worker thread for AI API calls to prevent blocking UI.
    """

    # Signals
    response_received = pyqtSignal(str)  # Emitted when response is received
    error_occurred = pyqtSignal(str)  # Emitted when error occurs

    def __init__(self, client: 'AIClient', messages: List[Dict], parent=None):
        super().__init__(parent)
        self.client = client
        self.messages = messages

    def run(self):
        """Execute AI API call in background thread."""
        try:
            response = self.client._call_api(self.messages)
            self.response_received.emit(response)
        except Exception as e:
            self.error_occurred.emit(str(e))


class AIClient(QObject):
    """
    AI Client for communicating with LLM APIs.
    Supports OpenAI and compatible APIs (DeepSeek, Claude, etc.).
    """

    # Signals
    response_received = pyqtSignal(str)  # Emitted when response is received
    error_occurred = pyqtSignal(str)  # Emitted when error occurs

    # System prompt for Linux operations assistant
    DEFAULT_SYSTEM_PROMPT = """ä½ æ˜¯ä¸€åä¸“ä¸šçš„ Linux ç³»ç»Ÿè¿ç»´ä¸“å®¶ï¼Œæ‹¥æœ‰ 10 å¹´ä»¥ä¸Šçš„å®æˆ˜ç»éªŒã€‚

## æ ¸å¿ƒå·¥ä½œåŸåˆ™

### 1. åˆ†æ­¥éª¤è§£å†³é—®é¢˜
å½“ç”¨æˆ·è¯¢é—®å¦‚ä½•å®ŒæˆæŸä¸ªä»»åŠ¡æ—¶ï¼Œè¯·æŒ‰ä»¥ä¸‹æ–¹å¼å›ç­”ï¼š

**æ­¥éª¤åŒ–å›ç­”æ¨¡å¼ï¼š**
```
### ç¬¬ 1 æ­¥ï¼š[æ­¥éª¤åç§°] - [ç®€çŸ­è¯´æ˜]

**æ“ä½œç›®çš„ï¼š** ç®€è¦è¯´æ˜è¿™ä¸€æ­¥è¦åšä»€ä¹ˆ

**æ‰§è¡Œå‘½ä»¤ï¼š**
```bash
[ç¬¬ä¸€ä¸ªå‘½ä»¤]
```

[å¿…è¦çš„å‚æ•°è¯´æ˜æˆ–æ³¨æ„äº‹é¡¹]

--- ç­‰å¾…æ‰§è¡Œç»“æœ ---
```

ç„¶ååœæ­¢ï¼Œç­‰å¾…ç”¨æˆ·æ‰§è¡Œå¹¶æŸ¥çœ‹ç»“æœåï¼Œå†ç»§ç»­ä¸‹ä¸€æ­¥ã€‚

### 2. ä¸Šä¸‹æ–‡æ„ŸçŸ¥
ä½ å¯ä»¥å®æ—¶çœ‹åˆ°ç”¨æˆ·çš„ç»ˆç«¯å±å¹•è¾“å‡ºã€‚
- **å¦‚æœå‘½ä»¤æ‰§è¡ŒæˆåŠŸ**ï¼Œç»§ç»­ä¸‹ä¸€æ­¥
- **å¦‚æœå‘½ä»¤æ‰§è¡Œå¤±è´¥**ï¼Œåˆ†æé”™è¯¯åŸå› ï¼Œæä¾›æ›¿ä»£æ–¹æ¡ˆ
- **æ ¹æ®å®é™…è¾“å‡ºè°ƒæ•´åç»­æ­¥éª¤**

### 3. å‘½ä»¤æ ¼å¼è§„èŒƒ
- åªæä¾›å…·ä½“å¯æ‰§è¡Œçš„å‘½ä»¤ï¼Œç”¨ Markdown ä»£ç å—æ ¼å¼ï¼š```bash command ```
- **ä¸¥ç¦**ç›´æ¥åœ¨ä»£ç å—ä¸­è¯´æ˜æ–‡å­—ã€è§£é‡Šæˆ–ç¤ºä¾‹
- æ‰€æœ‰æ–‡å­—è¯´æ˜æ”¾åœ¨ä»£ç å—å¤–é¢
- å‘½ä»¤è¦å®Œæ•´ã€å¯ç›´æ¥å¤åˆ¶ç²˜è´´æ‰§è¡Œ

### 4. äº¤äº’èŠ‚å¥æ§åˆ¶
- **ä¸€æ¬¡åªç»™ä¸€ä¸ªå‘½ä»¤**ï¼Œé™¤éå¤šä¸ªå‘½ä»¤å¿…é¡»è¿ç»­æ‰§è¡Œ
- æ¯ä¸ªå‘½ä»¤åæ˜ç¡®æ ‡æ³¨ "--- ç­‰å¾…æ‰§è¡Œç»“æœ ---"
- ä¸è¦ä¸€æ¬¡ç»™å‡ºé•¿ä¸²å‘½ä»¤åˆ—è¡¨
- è®©ç”¨æˆ·æŒ‰æ­¥éª¤æ‰§è¡Œï¼Œæ ¹æ®å®é™…åé¦ˆè°ƒæ•´

### 5. èƒ½åŠ›èŒƒå›´è¯´æ˜
ç”¨æˆ·é—®ä½ "ä½ èƒ½åšä»€ä¹ˆ"æ—¶ï¼Œè¯·ç®€æ´åˆ—ä¸¾æ ¸å¿ƒèƒ½åŠ›ï¼š
- ğŸ“Š ç³»ç»Ÿç›‘æ§ï¼ˆCPUã€å†…å­˜ã€ç£ç›˜ã€ç½‘ç»œï¼‰
- ğŸ”§ æ•…éšœè¯Šæ–­ï¼ˆæ—¥å¿—åˆ†æã€è¿›ç¨‹ç®¡ç†ã€æœåŠ¡ç®¡ç†ï¼‰
- ğŸ›¡ï¸ å®‰å…¨ç®¡ç†ï¼ˆé˜²ç«å¢™ã€æƒé™ã€SSH å¯†é’¥ï¼‰
- ğŸ“¦ è½¯ä»¶ç®¡ç†ï¼ˆå®‰è£…ã€æ›´æ–°ã€é…ç½®ï¼‰
- ğŸŒ ç½‘ç»œé…ç½®ï¼ˆç½‘å¡ã€è·¯ç”±ã€DNSã€ç«¯å£ï¼‰
- ğŸ’¾ æ•°æ®ç®¡ç†ï¼ˆå¤‡ä»½ã€æ¢å¤ã€å‹ç¼©ã€åŒæ­¥ï¼‰
- ğŸ“ æ—¥å¿—åˆ†æï¼ˆç³»ç»Ÿæ—¥å¿—ã€åº”ç”¨æ—¥å¿—ã€é”™è¯¯æ’æŸ¥ï¼‰

### 6. å®‰å…¨å‡†åˆ™
- æ¶‰åŠæ•°æ®åˆ é™¤ã€ç³»ç»Ÿä¿®æ”¹çš„æ“ä½œï¼Œå…ˆæ˜ç¡®è­¦å‘Šé£é™©
- ä¸è¦æ‰§è¡Œ `rm -rf /`ã€`dd`ã€`mkfs` ç­‰å±é™©å‘½ä»¤ï¼Œé™¤éç”¨æˆ·æ˜ç¡®è¦æ±‚
- å»ºè®®ä½¿ç”¨ `--dry-run` å‚æ•°é¢„æ¼” destructive æ“ä½œ
- ç”Ÿäº§ç¯å¢ƒæ“ä½œå‰æé†’å¤‡ä»½

### 7. ä¸“ä¸šå»ºè®®
- å‘½ä»¤ä¼˜å…ˆä½¿ç”¨ç°ä»£ Linux å‘è¡Œç‰ˆçš„é€šç”¨è¯­æ³•
- è¯´æ˜å‘½ä»¤çš„é€‚ç”¨åœºæ™¯å’Œé™åˆ¶æ¡ä»¶
- æä¾›å‘½ä»¤çš„æ›¿ä»£æ–¹æ¡ˆï¼ˆå¤šç§å·¥å…·å¯é€‰ï¼‰
- éµå¾ªæœ€å°æƒé™åŸåˆ™

## å½“å‰ä¼šè¯
ä½ å¯ä»¥çœ‹åˆ°ç”¨æˆ·çš„ç»ˆç«¯è¾“å‡ºï¼ˆterminal_contextï¼‰ï¼Œè¯·åŸºäºå®é™…æƒ…å†µç»™å‡ºç²¾å‡†çš„å»ºè®®ã€‚

å¼€å§‹å·¥ä½œå§ï¼æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ï¼Œä¸€æ­¥æ­¥ç»™å‡ºä¸“ä¸šçš„æŒ‡å¯¼ã€‚"""

    def __init__(self, parent=None):
        super().__init__(parent)

        # Load configuration from environment
        self.api_key = os.getenv('OPENAI_API_KEY', '')
        self.api_base = os.getenv('OPENAI_API_BASE', 'https://api.openai.com/v1')
        self.model = os.getenv('OPENAI_MODEL', 'gpt-4-turbo')

        # Debug: Print configuration
        print(f"[AI Client] Configuration loaded:")
        print(f"  API Key: {self.api_key[:10] if self.api_key else 'NOT SET'}...")
        print(f"  API Base: {self.api_base}")
        print(f"  Model: {self.model}")

        # Initialize OpenAI client
        self.client = None
        self._init_client()

        # Conversation history
        self.conversation_history: List[Dict] = []

    def _init_client(self):
        """Initialize OpenAI client with configured settings."""
        if not self.api_key:
            print("Warning: OPENAI_API_KEY not set in environment")
            return

        try:
            # Create OpenAI client (compatible with v1.0+)
            self.client = OpenAI(
                api_key=self.api_key,
                base_url=self.api_base
            )
            print(f"AI Client initialized: {self.api_base} with model {self.model}")
        except Exception as e:
            print(f"Failed to initialize AI client: {e}")
            self.client = None

    def is_configured(self) -> bool:
        """Check if AI client is properly configured."""
        # Just check if we have an API key, the client can be created when needed
        return bool(self.api_key)

    def _call_api(self, messages: List[Dict]) -> str:
        """
        Call the AI API and return response text.

        Args:
            messages: List of message dictionaries with 'role' and 'content'

        Returns:
            Response text from AI

        Raises:
            Exception: If API call fails
        """
        # Lazy initialization: create client when needed
        if not self.client:
            if not self.api_key:
                raise Exception("API Key not configured. Please set OPENAI_API_KEY in .env file")

            try:
                self.client = OpenAI(
                    api_key=self.api_key,
                    base_url=self.api_base
                )
                print(f"[AI Client] Lazy initialization successful")
            except Exception as e:
                raise Exception(f"Failed to initialize AI client: {str(e)}")

        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=0.7,
                max_tokens=2000
            )

            # Extract response text
            assistant_message = response.choices[0].message.content
            return assistant_message.strip()

        except Exception as e:
            raise Exception(f"API call failed: {str(e)}")

    def ask_async(self, user_message: str, terminal_context: str = ""):
        """
        Send question to AI asynchronously (non-blocking).

        Args:
            user_message: User's question
            terminal_context: Recent terminal output for context
        """
        # Build messages
        messages = self._build_messages(user_message, terminal_context)

        # Add to conversation history
        self.conversation_history.append({"role": "user", "content": user_message})

        # Create worker thread
        worker = AIResponseThread(self, messages, self)
        worker.response_received.connect(self._on_response_received)
        worker.error_occurred.connect(self._on_error)
        worker.start()

    def ask_sync(self, user_message: str, terminal_context: str = "") -> str:
        """
        Send question to AI synchronously (blocking).

        Args:
            user_message: User's question
            terminal_context: Recent terminal output for context

        Returns:
            AI response text
        """
        messages = self._build_messages(user_message, terminal_context)
        self.conversation_history.append({"role": "user", "content": user_message})

        response = self._call_api(messages)

        # Add to conversation history
        self.conversation_history.append({"role": "assistant", "content": response})

        return response

    def _build_messages(self, user_message: str, terminal_context: str) -> List[Dict]:
        """
        Build message list for API call.

        Args:
            user_message: User's question
            terminal_context: Recent terminal output

        Returns:
            List of message dictionaries
        """
        messages = []

        # System prompt
        messages.append({
            "role": "system",
            "content": self.DEFAULT_SYSTEM_PROMPT
        })

        # Add conversation history (excluding the last user message which will be added below)
        # This maintains context of the ongoing conversation
        # Keep only recent history to save tokens (last 10 messages = 5 turns)
        if len(self.conversation_history) >= 2:
            # Keep only the most recent 10 messages to save tokens while maintaining context
            recent_history = self.conversation_history[-10:] if len(self.conversation_history) > 10 else self.conversation_history[:-1]
            messages.extend(recent_history)

        # Add terminal context if available
        if terminal_context:
            context_msg = f"å½“å‰ç»ˆç«¯å±å¹•å†…å®¹ï¼š\n```\n{terminal_context}\n```\n\nç”¨æˆ·é—®é¢˜ï¼š{user_message}"
            messages.append({
                "role": "user",
                "content": context_msg
            })
        else:
            messages.append({
                "role": "user",
                "content": user_message
            })

        return messages

    def _on_response_received(self, response: str):
        """Handle response from worker thread."""
        # Add to conversation history
        self.conversation_history.append({"role": "assistant", "content": response})

        # Emit signal
        self.response_received.emit(response)

    def _on_error(self, error_msg: str):
        """Handle error from worker thread."""
        # Remove last user message from history since it failed
        if self.conversation_history and self.conversation_history[-1]["role"] == "user":
            self.conversation_history.pop()

        # Emit error signal
        self.error_occurred.emit(error_msg)

    def clear_history(self):
        """Clear conversation history."""
        self.conversation_history = []

    def set_config(self, api_key: str, api_base: str = None, model: str = None):
        """
        Update AI client configuration.

        Args:
            api_key: OpenAI API key
            api_base: API base URL (optional)
            model: Model name (optional)
        """
        self.api_key = api_key
        if api_base:
            self.api_base = api_base
        if model:
            self.model = model

        # Reinitialize client
        self._init_client()
